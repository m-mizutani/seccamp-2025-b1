# セキュリティ監視基盤の統合と段階的構築

**時間：9:25-9:45 (20分)**

## 🔗 基盤統一の必要性と効果

セキュリティ監視において、複数のデータソースを統合的に管理・分析することは、高度な脅威検知と効率的な運用の両立において不可欠です。しかし、その実装は組織の成熟度に応じて段階的に進める必要があります。

### ログ同士の突合（相関分析）の重要性

#### 単一ソースでは見えない攻撃パターン

攻撃者は複数のシステムを横断して活動することが一般的です。個別のログソースだけでは正常に見える行動も、複数のログを相関分析することで初めて異常として検知できます。

**🏫 無敗塾での実例**：
- **Google Workspace**: ログイン失敗を3回繰り返し
- **AWS Console**: 5分後に別アカウントでログイン成功
- **CloudTrail**: 直後にIAM権限昇格を試行

→ 個別には「よくある失敗」でも、時系列で見ると明確な攻撃パターン

#### 時系列相関による高度な検知

異なるシステムで発生した一見無関係なイベントも、時間軸で整理すると攻撃の全体像が見えてきます。

**攻撃シナリオの例**：
```
10:00 - Okta: 新規デバイスからのログイン（日本）
10:05 - Google Drive: 機密フォルダへの大量アクセス
10:15 - AWS S3: 通常の100倍のデータダウンロード
10:30 - Slack: 外部ドメインへのファイル送信
```

このような一連の行動は、個別システムでは検知困難ですが、統合基盤では容易に発見できます。

#### 複合的な内部脅威の検知

内部不正は正規の認証情報を使用するため、単独のシステムでは検知が困難です。

**検知可能なパターン**：
- 役職・部門を超えたアクセス（人事部員が開発リポジトリにアクセス）
- 通常業務時間外の大量データアクセス
- 退職予定者の異常な情報収集行動

### 管理の集約による運用効率化

#### 一元的なアラート管理

**分散管理の課題**：
- 各システムからの通知が個別に届き、重要度の判断が困難
- 同一インシデントに対する重複アラート
- 通知疲れによる重要アラートの見逃し

**統合管理のメリット**：
- 優先度付けされた単一のアラートキュー
- 関連アラートの自動グルーピング
- エスカレーションルールの統一

#### 統一されたダッシュボード

複数システムの状況を単一画面で把握することで、セキュリティ状況の全体像を即座に理解できます。

**ダッシュボードに含めるべき要素**：
- リアルタイムの脅威インジケーター
- 過去24時間のインシデントサマリー
- システム別のヘルスステータス
- 対応待ちアラートの優先度別リスト

#### スキル・知識の集約

**分散環境での課題**：
- 各システム固有の検索言語（SPL、KQL、SQL等）の習得が必要
- ツールごとの操作方法の学習コスト
- チーム間での知識共有の困難さ

**統合環境でのメリット**：
- 標準化されたクエリ言語（SQL）での統一的な分析
- 共通化された運用手順
- ナレッジの蓄積と再利用の促進

## 📊 スキーマ共通化のメリット・デメリット

### 👍 メリット

#### クエリの汎用性

標準化されたスキーマにより、同一のSQLクエリで複数のデータソースを横断的に検索できます。

**実例：全システムでの管理者アクティビティ検索**
```sql
-- OCSF形式での統一クエリ
SELECT 
    time,
    actor.user.email_addr,
    api.operation,
    class_name,
    severity_id
FROM unified_security_logs
WHERE severity_id >= 3  -- 中以上の重要度
    AND actor.user.type = 'Admin'
    AND time > current_timestamp - interval '24' hour
ORDER BY time DESC
```

#### 検知ルールの再利用

一度作成した検知ロジックを、異なるログソースに対しても適用できます。

**再利用可能な検知パターン**：
- 大量データアクセスの検知
- 権限昇格の試行
- 地理的異常アクセス
- 時間外アクティビティ

#### 分析ツールの統一

共通フォーマットにより、以下のツールを全データソースで利用可能：
- BIツール（Tableau、QuickSight等）
- 機械学習プラットフォーム
- 自動化されたレポーティング

### 👎 デメリット

#### 変換処理のオーバーヘッド

**パフォーマンスへの影響**：
- ETL処理による数分〜数十分の遅延（リアルタイム性への影響）
- 大量データ処理時のコンピュートコスト

**スキーマ管理のメンテナンス**
- ログ提供元の都合でスキーマが変更される
- スキーマ変更に追随する必要がある → メンテコストの上昇

**共通化したスキーマの整合性**
- 送信元IPアドレス、宛先IPアドレスがある → じゃあ多段reverse proxyのIPアドレスはどう表現する？
- ユーザID → UID or ユーザ名のどちらかしか提供されない

#### 元データの情報損失

標準化の過程で、ソース固有の詳細情報が失われる可能性があります。

**情報損失の例**：
- カスタムフィールドの欠落
- 詳細なエラーコード
- ベンダー固有の拡張情報

**対策**：
- 重要な元データは`unmapped`フィールドに保持
- 詳細調査時は元ログへのリンクを保持
- 必要に応じて拡張スキーマを定義

#### ソース固有機能の制約

各システムが持つ高度な分析機能を十分に活用できない場合があります。

**制約の例**：
- CloudTrailのInsights機能
- GuardDutyの機械学習モデル
- 各SaaSの組み込み分析機能

## 🎓 無敗塾における段階的統合戦略

組織の成熟度に応じた現実的なアプローチを、無敗塾の成長過程を例に解説します。

### フェーズ1（創業期）：システムごとのログ保全

**特徴**：
- リソース（人・予算）が限定的
- セキュリティ専任者不在
- 最低限の証跡保全が目標

**実装内容**：
```
基本方針：「とにかくログを失わない」

✅ CloudTrail有効化（全リージョン）
✅ S3バケットへの長期保存設定
✅ Google Workspace監査ログの有効化
✅ 90日以上の保持期間設定
```

**この段階での注意点**：
- 完璧を求めず、まずは保全を優先
- コスト最適化（S3 Glacier等の活用）
- 将来の統合を見据えた命名規則

### フェーズ2（事業拡大期）：可能な範囲でのログ収集と保全、マニュアルでの検査

**特徴**：
- セキュリティ担当者の配置（1-2名）
- 基本的なインシデント対応の必要性
- コンプライアンス要求の発生

**実装内容**：
```
拡張方針：「重要ログの収集と定期的な確認」

✅ 主要SaaSのログ収集自動化
  - Google Workspace → S3（日次バッチ）
  - Okta → S3（API経由）
✅ 週次でのマニュアルレビュー
  - 管理者アクティビティ
  - 失敗ログインの集計
  - 大量データアクセス
✅ 簡易的なアラート設定
  - CloudWatch Alarms
  - 閾値ベースの通知
```

**運用の工夫**：
- スプレッドシートでの簡易分析
- 重要イベントのチェックリスト化
- インシデント時の調査手順書作成

### フェーズ3（市場拡大期）：包括的統合によるログ収集・保全と検知システムの導入

**特徴**：
- セキュリティチームの発足（3-5名）
- 24時間365日の監視要求
- 高度な脅威への対応必要性

**実装内容**：
```
統合方針：「自動化された検知と迅速な対応」

✅ Security Lake導入
  - 全ログソースのOCSF変換
  - Athenaでの統合分析基盤
✅ 自動検知ルールの実装
  - 時系列相関分析
  - 異常検知アルゴリズム
  - カスタムビジネスルール
✅ SOAR連携
  - 自動初動対応
  - エスカレーション自動化
✅ 統合ダッシュボード
  - リアルタイム監視
  - KPIモニタリング
```

**この段階での課題と対策**：
- 誤検知の調整に時間をかける
- 段階的なルール追加
- 定期的な有効性評価

### フェーズ4-5（専門・グローバル展開）：専門チームの編成と継続的改善

**特徴**：
- 専門セキュリティ組織（10名以上）
- グローバル展開による24時間体制
- 先進的な脅威への対応

**実装内容**：
```
高度化方針：「予測的セキュリティと自動化」

✅ AI/ML活用
  - 行動ベースライン学習
  - 異常スコアリング
  - 予測的脅威検知
✅ 脅威インテリジェンス統合
  - 外部脅威情報の自動取り込み
  - IOCベースの自動検知
✅ セキュリティオーケストレーション
  - 完全自動化された初動対応
  - プレイブック駆動の対応
✅ 継続的改善プロセス
  - 月次での検知ルール見直し
  - 四半期でのアーキテクチャ評価
  - 年次でのゼロベース見直し
```

**成熟度の指標**：
- MTTD（平均検知時間）: 5分以内
- MTTR（平均対応時間）: 30分以内
- 誤検知率: 5%以下
- 自動化率: 80%以上

## 📈 段階的アプローチのベストプラクティス

### 1. 現在地の正確な把握

組織の現状を客観的に評価し、無理のない計画を立てることが重要です。

**評価項目**：
- 利用可能なリソース（人材、予算、時間）
- 現在の脅威レベルと事業リスク
- コンプライアンス要件
- 技術的成熟度

### 2. 小さな成功の積み重ね

完璧な統合基盤を一度に構築しようとせず、段階的な改善を重視します。

**推奨アプローチ**：
- 最も重要な2-3のログソースから開始
- 基本的な検知ルールから実装
- 成功体験をチーム内で共有
- 徐々に範囲を拡大

### 3. 将来を見据えた設計

初期段階から、将来の拡張を考慮した設計を心がけます。

**考慮すべき点**：
- 標準的な命名規則の採用
- スケーラブルなアーキテクチャ
- ベンダーロックインの回避
- ドキュメント化の徹底

### 4. 継続的な改善文化の醸成

セキュリティ監視は一度構築したら終わりではなく、継続的な改善が必要です。

**改善サイクル**：
- 定期的な有効性評価
- インシデントからの学習
- 新しい脅威への適応
- 技術進化への追従

## 🚀 次のステップ

理論編で学んだ統合監視基盤の概念を、実際のAWS環境で体験していきます。次のセクションでは、Security Lakeを使用した実践的な実装を行い、統合されたログデータから脅威を検知する方法を学びます。

統合基盤の構築は長い道のりですが、段階的なアプローチにより、どの組織でも実現可能です。重要なのは、現在の成熟度に応じた適切な目標設定と、継続的な改善への取り組みです。